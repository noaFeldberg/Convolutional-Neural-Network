# -*- coding: utf-8 -*-
"""Assignment 2- CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oe2RFNJ7OIkjjFWAYotfybI3iMFA0bQU

**CNN over Fasion MNIST**

In this assignment you are requested to build a convolutional network and train it over the Fasion MNIST data, which is a collection of 28X28 back and white images, classified into 10 different classes of clothing items. For more information about Fashion MNIST you may refer to: 
https://github.com/zalandoresearch/fashion-mnist
"""

# Loading Fashion MNIST
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt

trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,
                                        download=True, transform=transforms.ToTensor())

testset = torchvision.datasets.FashionMNIST(root='./data', train=False,
                                       download=True, transform=transforms.ToTensor())

classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress',
           'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')

# Use dataloaders for train and test (batch size is 4)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True)

testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False)

# The images are of 1 (depth), 28(width), 28(lenght) size (only one black-white channel)
trainset[0][0].shape

"""Here is what you need to do; you are encoureged to look at notebook "DL Notebook 9 - CIFAR CNN" when trying to complete the next steps.


Write a network CNNFMnist, that has the following architecture:

* Convolution with 10 3X3 filters
* Relu
* Max pool with 2X2
* Convolution with 5 3X3 filters
* Relu
* Convolution with 16 3X3 filters
* Relu
* Max pool with 2X2
* Liner, output size 128
* Relu
* Liner, output size 64
* Relu
* Liner, output size 10
"""

# Building the network with the architecture written above
class CNNFMnist(nn.Module):

    def __init__(self):
        super(CNNFMnist, self).__init__()
        # applies a 2D convolution over an input signal conposed of several input planes
        self.conv1 = nn.Conv2d(1,10,3)   # 1 input img, 10 output channels, 3x3 square convolution
        self.conv2 = nn.Conv2d(10,5,3)
        self.conv3 = nn.Conv2d(5,16,3)

        # fully connected layers - applies a linear transforamtion
        # Linear(size of input sampel, size of output sampel)
        self.fc1 = nn.Linear(16*4*4,128)       
        self.fc2 = nn.Linear(128,64)
        self.fc3 = nn.Linear(64,10)

    def forward(self, x):
        # applies a 2D convolution on x, then relu and then max pooling over a (2, 2) window
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))
        # turn x to vector:
        x = x.view(-1, self.num_flat_features(x))
        # applies liner transforamtion on x then relu 
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        return x
    
    # turn x to vector (fetures)
    def num_flat_features(self,x):
        # all dimensions except the batch dimension
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *= s
        return num_features

"""Write a code that trains the network with FashionMNIST train dataset, for classification (use cross entropy, and SGD).
Run the network for at least 10 epochs, over the entire dataset. Make sure to print the loss over the train set as well as the **test set** over time (say, every 1000 batches, but it's up to you), so you will know where you are during training. 

Note, measuring loss of test is similar to measuring loss over the train test. However, make sure not to run the test images in back propagation. Use them only in forward and calulate the average loss over the entire test set. Since it will make the training process run slower, you should measure loss for the test set only at the end of an epoch (so overall you get 10 loss values for the test set). You are encoureged to write a different function for claculating the loss of the test set, and then call it from the training procedure.


You should collect the loss values in an array, so you can plot then into two curves, one for train and one for test.

In addition, you should measure the time it takes you to train the network completely.
"""

net = CNNFMnist().cuda()     # -- For GPU
#net = CNNFMnist()            # -- For CPU

print(net)

# define loss function
criterion = nn.CrossEntropyLoss()

# define the optimizer
optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

# Your code goes here
import time

start_time = time.time()
loss_train = []
loss_test = []
imgCount = 0
img_axis_x=[]

for epoch in range(10):  

    running_loss_train = 0.0
    running_loss_test = 0.0
    lossPerEpoch_train = 0.0
    lossPerEpoch_test = 0.0

    # calculate the train's loss
    for i, data in enumerate(trainloader, 0):
        imgCount += 1
        # get the inputs
        inputs, labels = data
        
        inputs = inputs.cuda() # -- For GPU
        labels = labels.cuda() # -- For GPU

        #inputs = inputs  # -- For CPU
        #labels = labels  # -- For CPU

        # zero the parameter gradients
        optimizer.zero_grad()
        # forward 
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        # backward
        loss.backward()
        # optimize
        optimizer.step()

        # print statistics per 1000 images
        running_loss_train += loss.item()
        if (i+1) % 1000 == 0:    
            print('[%d, %5d] train loss per 1000 images: %.3f' %
                  (epoch + 1, i + 1, running_loss_train / 1000))
            # train loss per 1000 images
            loss_train.append(running_loss_train / 1000)
            img_axis_x.append(imgCount/10)
            running_loss_train = 0.0

    
    # calculate the test's loss
    for i, data in enumerate(testloader,0):
        # get the inputs
        inputs, labels = data
        inputs = inputs.cuda()   # -- For GPU
        labels = labels.cuda()   # -- For GPU

        #inputs = inputs  # -- For CPU
        #labels = labels  # -- For CPU

        # forward
        outputs = net(inputs)
        loss = criterion(outputs,labels)

        # print statisics per epoch
        running_loss_test += loss.item()   

    print('[%d] test loss per epoch: %.3f' %
          (epoch + 1, running_loss_test/2500))
    loss_test.append(running_loss_test/2500)
      
train_time = time.time() - start_time
print('Finished Training')
print('Total Training Time Is: %.3f seconds' % train_time)

# train curve
print('Train Curve')
img_axis_x = np.asarray(img_axis_x)
epochArr=np.arange(1,11)
plt.plot(img_axis_x, np.asarray(loss_train), c='blue')
plt.xlabel('Images')
plt.ylabel('Loss')
plt.show()

# test curve
print('Test Curve')
epochArr=np.arange(1,11)
plt.plot(epochArr, np.asarray(loss_test), c='red')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

"""Write a function that evaluates the resulted model over the entire test data of FashionMNIST. Provide a single accuracy number."""

correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        images = images.cuda()  # -- for GPU
        labels = labels.cuda()  # -- for GPU

        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('The networks accuracy on the test images: %d %%' % (100 * correct / total))

"""# Training with a GPU 
You are requested to change your code to use the GPU instead of the CPU.
This can be easily done bu converting every torch.tensor to torch.cuda.tensor. 

Specific instructions:
* Change the hardware equipent of your colab notebook. To do that, go to the "Runtime" menu, and then to "Change runtime type". In the dialog box, change "Hardware accelerator" to GPU.
* Please follow the lines that were commented out with the comment    # -- For GPU
* Also, remove the lines that have the comment # -- For CPU

Train your network again and compare training time.

# Submission instructions

You should submit a pdf file with the following items:

CPU Experiment:
*   Plot of loss curves (train in blue, test in red)
*   Training time

GPU Experiment:
*   Plot of loss curves (train in blue, test in red)
*   Training time

Link for your collab notebook.
ID and names of submitters.


Good luck!
"""